{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import re\n",
    "from pyspark.sql import SparkSession # type: ignore\n",
    "from pyspark.sql import functions as F # type: ignore\n",
    "from pyspark.sql.functions import col,udf # type: ignore\n",
    "from pyspark.sql.types import IntegerType,StringType # type: ignore\n",
    "from unidecode import unidecode # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "\n",
    "df_senasa = pd.read_excel(r\"Diccionario-Senasa_2024-09-28_CC.xlsx\")\n",
    "#df_veritrade=pd.read_excel(\"Veritrade_CMEDRANO@BIOMONT.COM.PE_PE_I_20240828163144_LIDA.xlsx\",header=5)\n",
    "#df_veritrade=pd.read_excel(r\"Data_ExportacionesCompetidoresGeriax.xlsx\",header=5)\n",
    "df_veritrade=pd.read_excel(r\"Data_ExportacionesCompetidoresGeriax.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "print(\"SPARK_HOME:\", os.environ.get('SPARK_HOME'))\n",
    "print(\"HADOOP_HOME:\", os.environ.get('HADOOP_HOME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_veritrade.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PYSPARK ACEPTA SOLO FECHAS ENTRE 1970 y 2038"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Pandas to PySpark DataFrame\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.network.timeout\", \"800s\") \\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"60s\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#spark.conf.set(\"spark.network.timeout\", \"800s\")\n",
    "#spark.conf.set(\"spark.sql.shuffle.partitions\", \"200\")\n",
    "\n",
    "df_senasa_spark = spark.createDataFrame(df_senasa)\n",
    "df_veritrade_spark = spark.createDataFrame(df_veritrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/19 13:05:56 WARN Utils: Your hostname, hadoop resolves to a loopback address: 127.0.1.1; using 192.168.1.103 instead (on interface enp0s3)\n",
      "24/11/19 13:05:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/19 13:05:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Basic Example\") \\\n",
    "    .config(\"spark.driver.memory\", \"3g\") \\\n",
    "    .config(\"spark.executor.memory\", \"3g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"1g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\",\"0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df_senasa_spark = spark.createDataFrame(df_senasa)\n",
    "df_veritrade_spark = spark.createDataFrame(df_veritrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade setuptools wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senasa_spark=df_senasa_spark.repartition(100)\n",
    "df_senasa_spark=df_senasa_spark.coalesce(50)\n",
    "\n",
    "df_veritrade_spark=df_veritrade_spark.repartition(100)\n",
    "df_veritrade_spark=df_veritrade_spark.coalesce(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver Memory:  3g\n",
      "Executor Memory:  3g\n",
      "Executor Memory:  2\n",
      "Executor Memory:  true\n",
      "Executor Memory:  1g\n"
     ]
    }
   ],
   "source": [
    "print(\"Driver Memory: \", spark.sparkContext.getConf().get(\"spark.driver.memory\"))\n",
    "print(\"Executor Memory: \", spark.sparkContext.getConf().get(\"spark.executor.memory\"))\n",
    "print(\"Executor Memory: \", spark.sparkContext.getConf().get(\"spark.executor.cores\"))\n",
    "print(\"Executor Memory: \", spark.sparkContext.getConf().get(\"spark.memory.offHeap.enabled\"))\n",
    "print(\"Executor Memory: \", spark.sparkContext.getConf().get(\"spark.memory.offHeap.size\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 6) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de particiones en df_veritrade_spark: 50\n"
     ]
    }
   ],
   "source": [
    "num_particiones_veritrade = df_senasa_spark.rdd.getNumPartitions()\n",
    "print(f\"Número de particiones en df_veritrade_spark: {num_particiones_veritrade}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_senasa_spark.show(1)\n",
    "\n",
    "#df_veritrade_spark.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementar lógica restante del veritrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: long (nullable = true)\n",
      " |-- N_PROD_PAGINA: long (nullable = true)\n",
      " |-- TIPO_PRODUCTO: string (nullable = true)\n",
      " |-- NOMBRE_COMERCIAL: string (nullable = true)\n",
      " |-- REPETIDO: long (nullable = true)\n",
      " |-- EMPRESA_RESPONSABLE_REGISTRO: string (nullable = true)\n",
      " |-- N_REGISTRO: string (nullable = true)\n",
      " |-- FECHA_VENCIMIENTO: string (nullable = true)\n",
      " |-- ETIQUETA: long (nullable = true)\n",
      " |-- VAR1: string (nullable = true)\n",
      " |-- DETALLE_VAR1: string (nullable = true)\n",
      " |-- VAR2: string (nullable = true)\n",
      " |-- DETALLE_VAR2: string (nullable = true)\n",
      " |-- VAR3: string (nullable = true)\n",
      " |-- DETALLE_VAR3: string (nullable = true)\n",
      " |-- VAR4: string (nullable = true)\n",
      " |-- DETALLE_VAR4: string (nullable = true)\n",
      " |-- VAR5: string (nullable = true)\n",
      " |-- DETALLE_VAR5: string (nullable = true)\n",
      " |-- VAR6: string (nullable = true)\n",
      " |-- DETALLE_VAR6: string (nullable = true)\n",
      " |-- VAR7: string (nullable = true)\n",
      " |-- DETALLE_VAR7: string (nullable = true)\n",
      " |-- VAR8: string (nullable = true)\n",
      " |-- DETALLE_VAR8: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_senasa_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Partida Aduanera: long (nullable = true)\n",
      " |-- Descripcion de la Partida Aduanera: string (nullable = true)\n",
      " |-- Aduana: string (nullable = true)\n",
      " |-- DUA / DAM: string (nullable = true)\n",
      " |-- Fecha: timestamp (nullable = true)\n",
      " |-- Cod. Tributario: long (nullable = true)\n",
      " |-- Exportador: string (nullable = true)\n",
      " |-- Importador: string (nullable = true)\n",
      " |-- Kg Bruto: double (nullable = true)\n",
      " |-- Kg Neto: double (nullable = true)\n",
      " |-- Qty 1: double (nullable = true)\n",
      " |-- Und 1: string (nullable = true)\n",
      " |-- Qty 2: long (nullable = true)\n",
      " |-- Und 2: string (nullable = true)\n",
      " |-- U$ FOB Tot: double (nullable = true)\n",
      " |-- U$ FOB Und 1: double (nullable = true)\n",
      " |-- U$ FOB Und 2: double (nullable = true)\n",
      " |-- Pais de Destino: string (nullable = true)\n",
      " |-- Puerto de destino: string (nullable = true)\n",
      " |-- Último Puerto Embarque: double (nullable = true)\n",
      " |-- Via: string (nullable = true)\n",
      " |-- Agente Portuario: string (nullable = true)\n",
      " |-- Agente de Aduana: string (nullable = true)\n",
      " |-- Descripcion Comercial: string (nullable = true)\n",
      " |-- Descripcion1: string (nullable = true)\n",
      " |-- Descripcion2: string (nullable = true)\n",
      " |-- Descripcion3: string (nullable = true)\n",
      " |-- Descripcion4: string (nullable = true)\n",
      " |-- Descripcion5: string (nullable = true)\n",
      " |-- Naviera: string (nullable = true)\n",
      " |-- Agente Carga(Origen): string (nullable = true)\n",
      " |-- Agente Carga(Destino): string (nullable = true)\n",
      " |-- Canal: string (nullable = true)\n",
      " |-- Mes: string (nullable = true)\n",
      " |-- Año: long (nullable = true)\n",
      " |-- A: string (nullable = true)\n",
      " |-- B: string (nullable = true)\n",
      " |-- C: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_veritrade_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "caracteres_especiales = set()\n",
    "\n",
    "def encontrar_caracteres_especiales(nombre):\n",
    "    return {caracter for caracter in nombre if not re.match(r'[A-Za-z0-9 ]', caracter)}\n",
    "\n",
    "#Obteniendo los caracteres especiales existentes en los nombres de los productos\n",
    "caracteres_especiales = df_senasa_spark.select(col(\"NOMBRE_COMERCIAL\")) \\\n",
    "    .rdd.flatMap(lambda row: encontrar_caracteres_especiales(row[0])) \\\n",
    "    .distinct() \\\n",
    "    .collect()\n",
    "\n",
    "#print(\"Caracteres especiales encontrados:\", caracteres_especiales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contar_palabras(texto):\n",
    "    return len(texto.split()) if texto else 0\n",
    "\n",
    "contar_palabras_udf = udf(contar_palabras, IntegerType())\n",
    "\n",
    "df_senasa_spark = df_senasa_spark.withColumn(\"NUMERO_DE_PALABRAS\", contar_palabras_udf(col(\"NOMBRE_COMERCIAL\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_senasa_spark.select(\"NOMBRE_COMERCIAL\", \"NUMERO_DE_PALABRAS\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estandarizar_texto(texto):\n",
    "    texto=str(texto)\n",
    "    resultado=texto.replace(\"MDCMTO.\",\"\")\n",
    "    resultado=resultado.replace(\"MDCMTO\",\"\")\n",
    "    resultado=resultado.replace(\"MDCTO.\",\"\")\n",
    "    resultado=resultado.replace(\"MDCTO\",\"\")\n",
    "    resultado=resultado.strip()\n",
    "    resultado=resultado.upper()\n",
    "    resultado=unidecode(resultado)\n",
    "    caracteres_permitidos = ''.join(caracteres_especiales)\n",
    "    resultado = re.sub(r'[^A-Za-z0-9 ' + re.escape(caracteres_permitidos) + ']', '', resultado)\n",
    "    resultado = re.sub(r'\\s*\\d+(\\.\\d+)?\\s*MM', '', resultado)\n",
    "    resultado=resultado.replace(\"0\",\"O\")\n",
    "    resultado=resultado.replace(\",\",\" \")\n",
    "    resultado=resultado.replace(\"MATERIA PRIMA\",\"\")\n",
    "    return resultado\n",
    "\n",
    "estandarizar_texto_udf = udf(estandarizar_texto, StringType())\n",
    "\n",
    "df_senasa_spark = df_senasa_spark.withColumn(\"DES_PROD\", estandarizar_texto_udf(col(\"NOMBRE_COMERCIAL\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_senasa_spark.select(\"ID\",\"NOMBRE_COMERCIAL\", \"NUMERO_DE_PALABRAS\",\"DES_PROD\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veritrade_spark=df_veritrade_spark.withColumn(\"DES_COM\",estandarizar_texto_udf(col(\"Descripcion Comercial\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de particiones en df_veritrade_spark: 50\n"
     ]
    }
   ],
   "source": [
    "num_particiones_veritrade = df_veritrade_spark.rdd.getNumPartitions()\n",
    "print(f\"Número de particiones en df_veritrade_spark: {num_particiones_veritrade}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_veritrade_spark=df_veritrade_spark.coalesce(4)\n",
    "#df_veritrade_spark.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_veritrade_spark.select(\"Descripcion Comercial\", \"DES_COM\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_senasa_filtrado = df_senasa_spark.filter(col(\"NUMERO_DE_PALABRAS\")>=2)\n",
    "\n",
    "dic_senasa = {row['DES_PROD']: row['ID'] for row in df_senasa_filtrado.select('DES_PROD', 'ID').collect()}\n",
    "\n",
    "def detectar_producto(descripcion, producto):\n",
    "    palabras_producto = producto.split()\n",
    "    palabras_descripcion=descripcion.split()\n",
    "    set_artificio=set({})\n",
    "    for prod in palabras_producto:\n",
    "        for des in palabras_descripcion:\n",
    "            if des==prod:\n",
    "                set_artificio.add(des)\n",
    "    \n",
    "    if set(palabras_producto)==set_artificio:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def obtener_foreign_key(texto):\n",
    "    for nombre_producto in dic_senasa.keys():\n",
    "        if detectar_producto(texto, nombre_producto):\n",
    "            id_senasa = dic_senasa.get(nombre_producto)\n",
    "            return id_senasa\n",
    "    return None\n",
    "\n",
    "obtener_foreign_key_udf = udf(obtener_foreign_key, IntegerType())\n",
    "\n",
    "df_veritrade_spark = df_veritrade_spark.withColumn(\"FK_SENASA_ID\", obtener_foreign_key_udf(col(\"DES_COM\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_veritrade_spark.select(\"Descripcion Comercial\", \"DES_COM\",\"FK_SENASA_ID\").show(3)\n",
    "\n",
    "#df_veritrade_filtrado = df_veritrade_spark.filter(col(\"FK_SENASA_ID\").isNotNull())\n",
    "\n",
    "#df_veritrade_filtrado.select(\"Descripcion Comercial\", \"DES_COM\",\"FK_SENASA_ID\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: long (nullable = true)\n",
      " |-- N_PROD_PAGINA: long (nullable = true)\n",
      " |-- TIPO_PRODUCTO: string (nullable = true)\n",
      " |-- NOMBRE_COMERCIAL: string (nullable = true)\n",
      " |-- REPETIDO: long (nullable = true)\n",
      " |-- EMPRESA_RESPONSABLE_REGISTRO: string (nullable = true)\n",
      " |-- N_REGISTRO: string (nullable = true)\n",
      " |-- FECHA_VENCIMIENTO: string (nullable = true)\n",
      " |-- ETIQUETA: long (nullable = true)\n",
      " |-- VAR1: string (nullable = true)\n",
      " |-- DETALLE_VAR1: string (nullable = true)\n",
      " |-- VAR2: string (nullable = true)\n",
      " |-- DETALLE_VAR2: string (nullable = true)\n",
      " |-- VAR3: string (nullable = true)\n",
      " |-- DETALLE_VAR3: string (nullable = true)\n",
      " |-- VAR4: string (nullable = true)\n",
      " |-- DETALLE_VAR4: string (nullable = true)\n",
      " |-- VAR5: string (nullable = true)\n",
      " |-- DETALLE_VAR5: string (nullable = true)\n",
      " |-- VAR6: string (nullable = true)\n",
      " |-- DETALLE_VAR6: string (nullable = true)\n",
      " |-- VAR7: string (nullable = true)\n",
      " |-- DETALLE_VAR7: string (nullable = true)\n",
      " |-- VAR8: string (nullable = true)\n",
      " |-- DETALLE_VAR8: string (nullable = true)\n",
      " |-- NUMERO_DE_PALABRAS: integer (nullable = true)\n",
      " |-- DES_PROD: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_senasa_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_senasa_spark.createOrReplaceTempView(\"senasa\")\n",
    "senasa = spark.sql(\"SELECT * FROM senasa\")\n",
    "\n",
    "df_veritrade_spark.createOrReplaceTempView(\"veritrade\")\n",
    "veritrade = spark.sql(\"SELECT * FROM veritrade\")\n",
    "\n",
    "query=\"\"\"\n",
    "SELECT ver.*,sen.DES_PROD,sen.TIPO_PRODUCTO,sen.DETALLE_VAR1 AS COMPOSICION,sen.DETALLE_VAR2 AS CLASIFICACION,sen.DETALLE_VAR3 AS FORMA\n",
    "FROM veritrade ver\n",
    "LEFT JOIN senasa sen\n",
    "ON ver.FK_SENASA_ID=sen.ID\n",
    "\"\"\"\n",
    "\n",
    "df_veritrade_spark_ite1 = spark.sql(query)\n",
    "df_veritrade_spark_ite1=df_veritrade_spark_ite1.coalesce(60)\n",
    "df_veritrade_spark_ite1.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veritrade_spark_ite1=df_veritrade_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode # type: ignore\n",
    "\n",
    "def estandarizar_texto2(texto):\n",
    "    texto=str(texto)\n",
    "    resultado=texto.replace(\"MDCMTO.\",\"\")\n",
    "    resultado=resultado.replace(\"MDCMTO\",\"\")\n",
    "    resultado=resultado.replace(\"MDCTO.\",\"\")\n",
    "    resultado=resultado.replace(\"MDCTO\",\"\")\n",
    "    resultado=resultado.strip()\n",
    "    resultado=resultado.upper()\n",
    "    resultado=unidecode(resultado)\n",
    "    caracteres_permitidos = ''.join(\" \")\n",
    "    resultado = re.sub(r'[^A-Za-z0-9 ' + re.escape(caracteres_permitidos) + ']', ' ', resultado) #DEJA LETRAS Y NUMEROS Y ESPACIOS Y CAMBIA LOS CARACTERES NO PERMITIDOS POR ESPACIOS\n",
    "    resultado = re.sub(r'\\s*\\d+(\\.\\d+)?\\s*MM', '', resultado) #ELIMINAMOS NUMERO Y UNIDAD DE MEDIDA PUEDE CAUSAR CONFUNSION CON OTRO NOMBRE DE PRODUCTO MM 100\n",
    "    resultado=resultado.replace(\"0\",\"O\")\n",
    "    resultado=resultado.replace(\"MATERIA PRIMA\",\"\") #KEYWORD QUE PUEDEN CONFUNDIR CONSIDERAR QUE ESTA KEYWORD SOLO SE ELIMINE EN VERITRADE\n",
    "    resultado = re.sub(r'\\s+', ' ', resultado)  # Reemplazar múltiples espacios por uno\n",
    "    return resultado\n",
    "\n",
    "estandarizar_texto2_udf = udf(estandarizar_texto2, StringType())\n",
    "\n",
    "df_senasa_spark = df_senasa_spark.withColumn(\"DES_PROD2\", estandarizar_texto2_udf(col(\"NOMBRE_COMERCIAL\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_senasa_filtrado = df_senasa_spark.filter(col(\"NUMERO_DE_PALABRAS\")>=2)\n",
    "\n",
    "dic_senasa = {row['DES_PROD2']: row['ID'] for row in df_senasa_filtrado.select('DES_PROD2', 'ID').collect()}\n",
    "\n",
    "df_veritrade_spark_ite1 = df_veritrade_spark_ite1.withColumn(\n",
    "    \"FK_SENASA_ID\",\n",
    "    F.when(col(\"FK_SENASA_ID\").isNull(), obtener_foreign_key_udf(col(\"DES_COM\"))).otherwise(col(\"FK_SENASA_ID\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_senasa_spark.createOrReplaceTempView(\"senasa\")\n",
    "senasa = spark.sql(\"SELECT * FROM senasa\")\n",
    "\n",
    "df_veritrade_spark_ite1.createOrReplaceTempView(\"veritrade\")\n",
    "veritrade = spark.sql(\"SELECT * FROM veritrade\")\n",
    "\n",
    "query=\"\"\"\n",
    "SELECT ver.*,sen.DES_PROD,sen.TIPO_PRODUCTO,sen.DETALLE_VAR1 AS COMPOSICION,sen.DETALLE_VAR2 AS CLASIFICACION,sen.DETALLE_VAR3 AS FORMA\n",
    "FROM veritrade ver\n",
    "LEFT JOIN senasa sen\n",
    "ON ver.FK_SENASA_ID=sen.ID\n",
    "\"\"\"\n",
    "\n",
    "df_veritrade_spark_ite2 = spark.sql(query)\n",
    "df_veritrade_spark_ite2=df_veritrade_spark_ite2.coalesce(60)\n",
    "\n",
    "df_veritrade_spark_ite2.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veritrade_spark_ite2=df_veritrade_spark_ite1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estandarizar_texto3(texto):\n",
    "    texto=str(texto)\n",
    "    resultado=texto.replace(\"MDCMTO.\",\"\")\n",
    "    resultado=resultado.replace(\"MDCMTO\",\"\")\n",
    "    resultado=resultado.replace(\"MDCTO.\",\"\")\n",
    "    resultado=resultado.replace(\"MDCTO\",\"\")\n",
    "    resultado=resultado.strip()\n",
    "    resultado=resultado.upper()\n",
    "    resultado=unidecode(resultado)\n",
    "    resultado = re.sub(r'[^A-Za-z0-9]', ' ', resultado)\n",
    "    resultado = re.sub(r'\\s*\\d+(\\.\\d+)?\\s*MM', '', resultado)\n",
    "    resultado=resultado.replace(\"0\",\"O\")\n",
    "    resultado = re.sub(r'\\s+', ' ', resultado)\n",
    "    resultado=resultado.replace(\"MATERIA PRIMA\",\"\") #KEYWORD QUE PUEDEN CONFUNDIR CONSIDERAR QUE ESTA KEYWORD SOLO SE ELIMINE EN VERITRADE\n",
    "    return resultado\n",
    "\n",
    "estandarizar_texto3_udf = udf(estandarizar_texto3, StringType())\n",
    "\n",
    "df_senasa_spark = df_senasa_spark.withColumn(\"DES_PROD3\", estandarizar_texto3_udf(col(\"NOMBRE_COMERCIAL\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_senasa_filtrado = df_senasa_spark.filter(col(\"NUMERO_DE_PALABRAS\")==1)\n",
    "\n",
    "dic_senasa = {row['DES_PROD3']: row['ID'] for row in df_senasa_filtrado.select('DES_PROD3', 'ID').collect()}\n",
    "\n",
    "def detectar_producto2(descripcion, producto):\n",
    "    descripcion=str(descripcion)\n",
    "    producto=str(producto)\n",
    "\n",
    "    if descripcion.startswith(producto+\" \"):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def obtener_foreign_key2(texto):\n",
    "    for nombre_producto in dic_senasa.keys():\n",
    "        if detectar_producto2(texto, nombre_producto):\n",
    "            id_senasa = dic_senasa.get(nombre_producto)\n",
    "            return id_senasa\n",
    "    return None\n",
    "\n",
    "obtener_foreign_key2_udf = udf(obtener_foreign_key2, IntegerType())\n",
    "\n",
    "\n",
    "df_veritrade_spark_ite2 = df_veritrade_spark_ite2.withColumn(\n",
    "    \"FK_SENASA_ID\",\n",
    "    F.when(col(\"FK_SENASA_ID\").isNull(), obtener_foreign_key2_udf(col(\"DES_COM\"))).otherwise(col(\"FK_SENASA_ID\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_senasa_spark.createOrReplaceTempView(\"senasa\")\n",
    "senasa = spark.sql(\"SELECT * FROM senasa\")\n",
    "\n",
    "df_veritrade_spark_ite2.createOrReplaceTempView(\"veritrade\")\n",
    "veritrade = spark.sql(\"SELECT * FROM veritrade\")\n",
    "\n",
    "query=\"\"\"\n",
    "SELECT ver.*,sen.DES_PROD,sen.TIPO_PRODUCTO,sen.DETALLE_VAR1 AS COMPOSICION,sen.DETALLE_VAR2 AS CLASIFICACION,sen.DETALLE_VAR3 AS FORMA\n",
    "FROM veritrade ver\n",
    "LEFT JOIN senasa sen\n",
    "ON ver.FK_SENASA_ID=sen.ID\n",
    "\"\"\"\n",
    "\n",
    "df_veritrade_spark_ite3 = spark.sql(query)\n",
    "df_veritrade_spark_ite3=df_veritrade_spark_ite3.coalesce(60)\n",
    "\n",
    "df_veritrade_spark_ite3.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veritrade_spark_ite3=df_veritrade_spark_ite2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def estandarizar_texto4(texto):\n",
    "    texto=str(texto)\n",
    "    resultado=texto.replace(\"MDCMTO.\",\"\")\n",
    "    resultado=resultado.replace(\"MDCMTO\",\"\")\n",
    "    resultado=resultado.replace(\"MDCTO.\",\"\")\n",
    "    resultado=resultado.replace(\"MDCTO\",\"\")\n",
    "    resultado=resultado.strip()\n",
    "    resultado=resultado.upper()\n",
    "    resultado=unidecode(resultado)\n",
    "    caracteres_permitidos = ''.join(caracteres_especiales)\n",
    "    resultado = re.sub(r'[^A-Za-z0-9 ' + re.escape(caracteres_permitidos) + ']', '', resultado)\n",
    "    resultado = re.sub(r'\\s*\\d+(\\.\\d+)?\\s*MM', '', resultado)\n",
    "    resultado=resultado.replace(\"0\",\"O\")\n",
    "    resultado=resultado.replace(\",\",\"\")\n",
    "    resultado=resultado.replace(\" \",\"\")\n",
    "    resultado=resultado.replace(\"MATERIA PRIMA\",\"\") #KEYWORD QUE PUEDEN CONFUNDIR CONSIDERAR QUE ESTA KEYWORD SOLO SE ELIMINE EN VERITRADE\n",
    "    return resultado\n",
    "\n",
    "estandarizar_texto4_udf = udf(estandarizar_texto4, StringType())\n",
    "\n",
    "df_senasa_spark = df_senasa_spark.withColumn(\"DES_PROD4\", estandarizar_texto4_udf(col(\"NOMBRE_COMERCIAL\")))\n",
    "\n",
    "dic_senasa = {row['DES_PROD4']: row['ID'] for row in df_senasa_spark.select('DES_PROD4', 'ID').collect()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_producto3(descripcion, producto):\n",
    "    descripcion=str(descripcion)\n",
    "    producto=str(producto)\n",
    "\n",
    "    if producto in descripcion:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def obtener_foreign_key3(texto):\n",
    "    for nombre_producto in dic_senasa.keys():\n",
    "        if detectar_producto3(texto, nombre_producto):\n",
    "            id_senasa = dic_senasa.get(nombre_producto)\n",
    "            return id_senasa\n",
    "    return None\n",
    "\n",
    "obtener_foreign_key3_udf = udf(obtener_foreign_key3, IntegerType())\n",
    "\n",
    "df_veritrade_spark_ite3 = df_veritrade_spark_ite3.withColumn(\n",
    "    \"FK_SENASA_ID\",\n",
    "    F.when(col(\"FK_SENASA_ID\").isNull(), obtener_foreign_key3_udf(col(\"DES_COM\"))).otherwise(col(\"FK_SENASA_ID\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veritrade_spark_ite4=df_veritrade_spark_ite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def estandarizar_texto5(texto):\n",
    "    texto=str(texto)\n",
    "    resultado=texto.replace(\"MDCMTO.\",\"\")\n",
    "    resultado=resultado.replace(\"MDCMTO\",\"\")\n",
    "    resultado=resultado.replace(\"MDCTO.\",\"\")\n",
    "    resultado=resultado.replace(\"MDCTO\",\"\")\n",
    "    resultado=resultado.strip()\n",
    "    resultado=resultado.upper()\n",
    "    resultado=unidecode(resultado)\n",
    "    resultado = re.sub(r'[^A-Za-z0-9]', '', resultado)\n",
    "    resultado = re.sub(r'\\s*\\d+(\\.\\d+)?\\s*MM', '', resultado)\n",
    "    resultado=resultado.replace(\"0\",\"O\")\n",
    "    resultado=resultado.replace(\",\",\"\")\n",
    "    resultado=resultado.replace(\" \",\"\")\n",
    "    resultado=resultado.replace(\"MATERIA PRIMA\",\"\") #KEYWORD QUE PUEDEN CONFUNDIR CONSIDERAR QUE ESTA KEYWORD SOLO SE ELIMINE EN VERITRADE\n",
    "    return resultado\n",
    "\n",
    "estandarizar_texto5_udf = udf(estandarizar_texto5, StringType())\n",
    "\n",
    "df_senasa_spark = df_senasa_spark.withColumn(\"DES_PROD5\", estandarizar_texto4_udf(col(\"NOMBRE_COMERCIAL\")))\n",
    "\n",
    "dic_senasa = {row['DES_PROD5']: row['ID'] for row in df_senasa_spark.select('DES_PROD5', 'ID').collect()}\n",
    "\n",
    "df_veritrade_spark_ite4 = df_veritrade_spark_ite4.withColumn(\n",
    "    \"FK_SENASA_ID\",\n",
    "    F.when(col(\"FK_SENASA_ID\").isNull(), obtener_foreign_key3_udf(col(\"DES_COM\"))).otherwise(col(\"FK_SENASA_ID\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_veritrade_spark_ite4.write.csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [Partida Aduanera#50L, Descripcion de la Partida Aduanera#51, Aduana#52, DUA / DAM#53, Fecha#54, Cod. Tributario#55L, Exportador#56, Importador#57, Kg Bruto#58, Kg Neto#59, Qty 1#60, Und 1#61, Qty 2#62L, Und 2#63, U$ FOB Tot#64, U$ FOB Und 1#65, U$ FOB Und 2#66, Pais de Destino#67, Puerto de destino#68, Último Puerto Embarque#69, Via#70, Agente Portuario#71, Agente de Aduana#72, Descripcion Comercial#73, ... 16 more fields]\n",
      "   +- BatchEvalPython [obtener_foreign_key3(DES_COM#185)#538], [pythonUDF0#584]\n",
      "      +- Project [Partida Aduanera#50L, Descripcion de la Partida Aduanera#51, Aduana#52, DUA / DAM#53, Fecha#54, Cod. Tributario#55L, Exportador#56, Importador#57, Kg Bruto#58, Kg Neto#59, Qty 1#60, Und 1#61, Qty 2#62L, Und 2#63, U$ FOB Tot#64, U$ FOB Und 1#65, U$ FOB Und 2#66, Pais de Destino#67, Puerto de destino#68, Último Puerto Embarque#69, Via#70, Agente Portuario#71, Agente de Aduana#72, Descripcion Comercial#73, ... 16 more fields]\n",
      "         +- BatchEvalPython [obtener_foreign_key3(DES_COM#185)#460], [pythonUDF0#583]\n",
      "            +- Project [Partida Aduanera#50L, Descripcion de la Partida Aduanera#51, Aduana#52, DUA / DAM#53, Fecha#54, Cod. Tributario#55L, Exportador#56, Importador#57, Kg Bruto#58, Kg Neto#59, Qty 1#60, Und 1#61, Qty 2#62L, Und 2#63, U$ FOB Tot#64, U$ FOB Und 1#65, U$ FOB Und 2#66, Pais de Destino#67, Puerto de destino#68, Último Puerto Embarque#69, Via#70, Agente Portuario#71, Agente de Aduana#72, Descripcion Comercial#73, ... 16 more fields]\n",
      "               +- BatchEvalPython [estandarizar_texto(Descripcion Comercial#73)#184, obtener_foreign_key(estandarizar_texto(Descripcion Comercial#73)#184)#230, obtener_foreign_key2(estandarizar_texto(Descripcion Comercial#73)#184)#383], [pythonUDF0#580, pythonUDF1#581, pythonUDF2#582]\n",
      "                  +- Coalesce 50\n",
      "                     +- Exchange RoundRobinPartitioning(100), REPARTITION_BY_NUM, [plan_id=462]\n",
      "                        +- Scan ExistingRDD[Partida Aduanera#50L,Descripcion de la Partida Aduanera#51,Aduana#52,DUA / DAM#53,Fecha#54,Cod. Tributario#55L,Exportador#56,Importador#57,Kg Bruto#58,Kg Neto#59,Qty 1#60,Und 1#61,Qty 2#62L,Und 2#63,U$ FOB Tot#64,U$ FOB Und 1#65,U$ FOB Und 2#66,Pais de Destino#67,Puerto de destino#68,Último Puerto Embarque#69,Via#70,Agente Portuario#71,Agente de Aduana#72,Descripcion Comercial#73,... 14 more fields]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/19 13:06:30 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "df_veritrade_spark_ite4.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de particiones en df_veritrade_spark: 50\n"
     ]
    }
   ],
   "source": [
    "num_particiones_veritrade = df_veritrade_spark_ite4.rdd.getNumPartitions()\n",
    "print(f\"Número de particiones en df_veritrade_spark: {num_particiones_veritrade}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "df_veritrade_spark_ite5=df_veritrade_spark_ite4.join(broadcast(df_senasa_spark),df_veritrade_spark_ite4.FK_SENASA_ID==df_senasa_spark.ID,\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- BroadcastHashJoin [cast(FK_SENASA_ID#539 as bigint)], [ID#0L], LeftOuter, BuildRight, false\n",
      "   :- Project [Partida Aduanera#50L, Descripcion de la Partida Aduanera#51, Aduana#52, DUA / DAM#53, Fecha#54, Cod. Tributario#55L, Exportador#56, Importador#57, Kg Bruto#58, Kg Neto#59, Qty 1#60, Und 1#61, Qty 2#62L, Und 2#63, U$ FOB Tot#64, U$ FOB Und 1#65, U$ FOB Und 2#66, Pais de Destino#67, Puerto de destino#68, Último Puerto Embarque#69, Via#70, Agente Portuario#71, Agente de Aduana#72, Descripcion Comercial#73, ... 16 more fields]\n",
      "   :  +- BatchEvalPython [obtener_foreign_key3(DES_COM#185)#538], [pythonUDF0#731]\n",
      "   :     +- Project [Partida Aduanera#50L, Descripcion de la Partida Aduanera#51, Aduana#52, DUA / DAM#53, Fecha#54, Cod. Tributario#55L, Exportador#56, Importador#57, Kg Bruto#58, Kg Neto#59, Qty 1#60, Und 1#61, Qty 2#62L, Und 2#63, U$ FOB Tot#64, U$ FOB Und 1#65, U$ FOB Und 2#66, Pais de Destino#67, Puerto de destino#68, Último Puerto Embarque#69, Via#70, Agente Portuario#71, Agente de Aduana#72, Descripcion Comercial#73, ... 16 more fields]\n",
      "   :        +- BatchEvalPython [obtener_foreign_key3(DES_COM#185)#460], [pythonUDF0#730]\n",
      "   :           +- Project [Partida Aduanera#50L, Descripcion de la Partida Aduanera#51, Aduana#52, DUA / DAM#53, Fecha#54, Cod. Tributario#55L, Exportador#56, Importador#57, Kg Bruto#58, Kg Neto#59, Qty 1#60, Und 1#61, Qty 2#62L, Und 2#63, U$ FOB Tot#64, U$ FOB Und 1#65, U$ FOB Und 2#66, Pais de Destino#67, Puerto de destino#68, Último Puerto Embarque#69, Via#70, Agente Portuario#71, Agente de Aduana#72, Descripcion Comercial#73, ... 16 more fields]\n",
      "   :              +- BatchEvalPython [estandarizar_texto(Descripcion Comercial#73)#184, obtener_foreign_key(estandarizar_texto(Descripcion Comercial#73)#184)#230, obtener_foreign_key2(estandarizar_texto(Descripcion Comercial#73)#184)#383], [pythonUDF0#727, pythonUDF1#728, pythonUDF2#729]\n",
      "   :                 +- Coalesce 50\n",
      "   :                    +- Exchange RoundRobinPartitioning(100), REPARTITION_BY_NUM, [plan_id=566]\n",
      "   :                       +- Scan ExistingRDD[Partida Aduanera#50L,Descripcion de la Partida Aduanera#51,Aduana#52,DUA / DAM#53,Fecha#54,Cod. Tributario#55L,Exportador#56,Importador#57,Kg Bruto#58,Kg Neto#59,Qty 1#60,Und 1#61,Qty 2#62L,Und 2#63,U$ FOB Tot#64,U$ FOB Und 1#65,U$ FOB Und 2#66,Pais de Destino#67,Puerto de destino#68,Último Puerto Embarque#69,Via#70,Agente Portuario#71,Agente de Aduana#72,Descripcion Comercial#73,... 14 more fields]\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, true]),false), [plan_id=582]\n",
      "      +- Project [ID#0L, N_PROD_PAGINA#1L, TIPO_PRODUCTO#2, NOMBRE_COMERCIAL#3, REPETIDO#4L, EMPRESA_RESPONSABLE_REGISTRO#5, N_REGISTRO#6, FECHA_VENCIMIENTO#7, ETIQUETA#8L, VAR1#9, DETALLE_VAR1#10, VAR2#11, DETALLE_VAR2#12, VAR3#13, DETALLE_VAR3#14, VAR4#15, DETALLE_VAR4#16, VAR5#17, DETALLE_VAR5#18, VAR6#19, DETALLE_VAR6#20, VAR7#21, DETALLE_VAR7#22, VAR8#23, ... 7 more fields]\n",
      "         +- BatchEvalPython [contar_palabras(NOMBRE_COMERCIAL#3)#127, estandarizar_texto(NOMBRE_COMERCIAL#3)#155, estandarizar_texto2(NOMBRE_COMERCIAL#3)#272, estandarizar_texto3(NOMBRE_COMERCIAL#3)#348, estandarizar_texto4(NOMBRE_COMERCIAL#3)#425], [pythonUDF0#732, pythonUDF1#733, pythonUDF2#734, pythonUDF3#735, pythonUDF4#736]\n",
      "            +- Coalesce 50\n",
      "               +- Exchange RoundRobinPartitioning(100), REPARTITION_BY_NUM, [plan_id=576]\n",
      "                  +- Filter isnotnull(ID#0L)\n",
      "                     +- Scan ExistingRDD[ID#0L,N_PROD_PAGINA#1L,TIPO_PRODUCTO#2,NOMBRE_COMERCIAL#3,REPETIDO#4L,EMPRESA_RESPONSABLE_REGISTRO#5,N_REGISTRO#6,FECHA_VENCIMIENTO#7,ETIQUETA#8L,VAR1#9,DETALLE_VAR1#10,VAR2#11,DETALLE_VAR2#12,VAR3#13,DETALLE_VAR3#14,VAR4#15,DETALLE_VAR4#16,VAR5#17,DETALLE_VAR5#18,VAR6#19,DETALLE_VAR6#20,VAR7#21,DETALLE_VAR7#22,VAR8#23,DETALLE_VAR8#24]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_veritrade_spark_ite5.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de particiones en df_veritrade_spark: 50\n"
     ]
    }
   ],
   "source": [
    "num_particiones_veritrade = df_veritrade_spark_ite5.rdd.getNumPartitions()\n",
    "print(f\"Número de particiones en df_veritrade_spark: {num_particiones_veritrade}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_senasa_spark.createOrReplaceTempView(\"senasa\")\n",
    "senasa = spark.sql(\"SELECT * FROM senasa\")\n",
    "\n",
    "df_veritrade_spark_ite4.createOrReplaceTempView(\"veritrade\")\n",
    "veritrade = spark.sql(\"SELECT * FROM veritrade\")\n",
    "\n",
    "query=\"\"\"\n",
    "SELECT ver.*,sen.DES_PROD,sen.TIPO_PRODUCTO,sen.DETALLE_VAR1 AS COMPOSICION,sen.DETALLE_VAR2 AS CLASIFICACION,sen.DETALLE_VAR3 AS FORMA\n",
    "FROM veritrade ver\n",
    "LEFT JOIN senasa sen\n",
    "ON ver.FK_SENASA_ID=sen.ID\n",
    "\"\"\"\n",
    "\n",
    "df_veritrade_spark_ite5 = spark.sql(query)\n",
    "df_veritrade_spark_ite5=df_veritrade_spark_ite5.coalesce(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificacion_alimento_en_des(texto):\n",
    "    texto = str(texto)\n",
    "    if texto.startswith(\"ALIMENTO\") or texto.startswith(\"ALMNTO.\") or \"ALIMENTO\" in texto:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def indicar_alimento(descripcion_comercial):\n",
    "    if verificacion_alimento_en_des(descripcion_comercial):\n",
    "        return \"Alimento\"\n",
    "    \n",
    "indicar_alimento_udf = udf(indicar_alimento, StringType())\n",
    "\n",
    "df_veritrade_spark_ite6 = df_veritrade_spark_ite5.withColumn(\n",
    "    \"TIPO_PRODUCTO\",\n",
    "    F.when(col(\"FK_SENASA_ID\").isNull(), indicar_alimento_udf(col(\"DES_COM\"))).otherwise(col(\"TIPO_PRODUCTO\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_veritrade_spark_ite6.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificacion_agricola_en_des(texto):\n",
    "    texto = str(texto)\n",
    "    if texto.startswith(\"AGRICOLA\") or texto.startswith(\"AGRÍCOLA\") or \"AGRICULTURA\" in texto:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def indicar_agricola(descripcion_comercial):\n",
    "    if verificacion_alimento_en_des(descripcion_comercial):\n",
    "        return \"Agrícola\"\n",
    "    \n",
    "indicar_agricola_udf = udf(indicar_agricola, StringType())\n",
    "\n",
    "df_veritrade_spark_ite6 = df_veritrade_spark_ite6.withColumn(\n",
    "    \"TIPO_PRODUCTO\",\n",
    "    F.when(col(\"FK_SENASA_ID\").isNull()| col(\"TIPO_PRODUCTO\").isNull(), indicar_agricola_udf(col(\"DES_COM\"))).otherwise(col(\"TIPO_PRODUCTO\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_particiones_veritrade = df_veritrade_spark_ite6.rdd.getNumPartitions()\n",
    "#print(f\"Número de particiones en df_veritrade_spark: {num_particiones_veritrade}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "\n",
    "#df_veritrade=pd.read_excel(\"VERITRADE_pruebas_01102024.xlsx\")\n",
    "#df_senasa=pd.read_excel(\"Diccionario-Senasa_2024-09-28_CC.xlsx\",sheet_name=\"2024-09-28\")\n",
    "\n",
    "# Crear un diccionario de tipos de presentación\n",
    "presentaciones = {\n",
    "    'AMPOLLA':['AMPOLLA '],\n",
    "    'BALDE':['BALDE '],\n",
    "    'BANDEJA':['BANDEJA '],\n",
    "    'BARRIL':['BARRIL '],\n",
    "    'BIDON': ['BIDON ', 'BIDONES ', 'BIDON(ES) '],\n",
    "    'BIG BAG': ['BIG BAG '],\n",
    "    'BLISTER':['BLISTER '],\n",
    "    'BLOQUE': ['BLOQUE ', 'BLOQUES ', 'BLOQUE(S) '],\n",
    "    'BOLSA':['BOLSA ','BOLSAS '],\n",
    "    'BOTELLA': ['BOTELLA ', 'BOTELLAS ', 'BOTELLA(S) ', 'BOTTLE ', 'BOTTLES ', 'BOTTLE(S) ', ' BOT '],\n",
    "    'CAJA': ['CAJA ', 'CAJAS ', 'CAJA(S) '],\n",
    "    'CILINDRO': ['CILINDRO ', 'CILINDROS ', 'CILINDRO(S) '],\n",
    "    'COJIN': ['COJIN '],\n",
    "    'COLLAR': ['COLLAR '],\n",
    "    'CONTENEDOR': ['CONTENEDOR '],\n",
    "    'DOY': ['DOY PACK '],\n",
    "    'ENVASE': ['ENVASE ', 'ENVASES ', 'ENVASE(S) '],\n",
    "    'ESTUCHE': ['ESTUCHE '],\n",
    "    'FLEXITANK': ['FLEXITANK '],\n",
    "    'FRASCO':['FRASCO ', 'FRASCOS ', 'FRASCO(S) ', \"FCO. \"],\n",
    "    'GALON': ['GALON ', 'GALONES ', 'GALON(ES) ', 'GALONERA ', 'GALONERA(S) '],\n",
    "    'GARRAFA': ['GARRAFA '],\n",
    "    'GRANEL': ['GRANEL '],\n",
    "    'ISOTANQUE': ['INSOTANQUE ','ISOTANQUES '],\n",
    "    'JERINGA': ['JERINGA ', 'JERINGAS ', 'JERINGA(S) '],\n",
    "    'LATA': ['LATA ','LATAS '],\n",
    "    'PIPETA': ['SPOT ON ', 'RIVOLTA ', 'PIPETA ', 'PIPETAS ', 'PIPETA(S) '],\n",
    "    'POMO': ['POMO ', 'POMOS ', 'POMO(S) '],\n",
    "    'POTE': ['POTE ', 'POTES ', 'POTE(S) '],\n",
    "    'POUCH': ['POUCH '],\n",
    "    'SACHET': ['SACHET '],\n",
    "    'SACO':['SACO ', 'SACOS ', 'SACO(S) '],\n",
    "    'SOBRE': ['SOBRE ', 'SOBRES ', 'SOBRE(S) '],\n",
    "    'TAMBOR': ['TAMBOR ', 'TAMBORES ', 'TAMBOR(ES) ', 'DRUM ', 'DRUMS ', 'DRUM(S) '],\n",
    "    'TANQUE': ['TANQUE '],\n",
    "    'TARRO': ['TARRO '],\n",
    "    'TUBO': ['TUBO ', 'TUBOS ', 'TUBO(S) '],\n",
    "    'VIAL': ['VIAL '],\n",
    "}\n",
    "\n",
    "unidades_dict = {\n",
    "    'KG': ['KG','KGS', 'KILOGRAMOS', 'KILOS'],\n",
    "    'GR': ['GR','GRAMOS','G','GRMS','GRS'],\n",
    "    'LT': ['LT', 'LTR','LTS','LTRS','LTROS', 'LITROS', 'LITRO','L'],\n",
    "    'ML': ['ML'],\n",
    "    #'UND':['UND'], #YA SABES QUE ES UNA UNIDAD PERO COMO SE SI ES TABLETA O COMPRIMIDO\n",
    "    #'TAB':['TAB','TABS','TABLETA','TABLETAS','PASTILLAS','COMP']\n",
    "}\n",
    "\n",
    "sinonimos_a_clave = {}\n",
    "for clave, sinonimos in unidades_dict.items():\n",
    "    for sinonimo in sinonimos:\n",
    "        sinonimos_a_clave[sinonimo] = clave\n",
    "\n",
    "#pattern = r'(?<!\\S)(\\d+(?:[.,]\\d+)?)\\s*(' + '|'.join(re.escape(unit.strip()) for units in unidades_dict.values() for unit in units) + r')\\b'\n",
    "pattern = r'(?<!\\S)(\\d+(?:[.,]\\d+)?)\\s*(' + '|'.join(re.escape(unit) for unit in sinonimos_a_clave.keys()) + r')\\b'\n",
    "pattern_solo_valor=r'(?<!\\S)(\\d+(?:[.,]\\d+)?)\\s*\\b'\n",
    "\n",
    "senasa_data = df_senasa_spark.select(\"ID\", \"DETALLE_VAR4\", \"DETALLE_VAR3\").collect()\n",
    "senasa_dict = {row.ID: (row.DETALLE_VAR4, row.DETALLE_VAR3) for row in senasa_data}\n",
    "\n",
    "def primeras_presentaciones_udf(id_senasa):\n",
    "    if id_senasa is None or id_senasa not in senasa_dict:\n",
    "        return\n",
    "    \n",
    "    presentacion, forma = senasa_dict[id_senasa]\n",
    "\n",
    "    if isinstance(presentacion, str):\n",
    "        try:\n",
    "            my_pre_list = ast.literal_eval(presentacion)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return\n",
    "        \n",
    "        if len(my_pre_list) == 1:\n",
    "            presentacion = my_pre_list[0].upper()\n",
    "            coincidencias = re.findall(pattern, presentacion)\n",
    "            valor = re.findall(pattern_solo_valor, presentacion)\n",
    "\n",
    "            if coincidencias:\n",
    "                resultados = [f\"{cantidad.replace(',', '.')} {sinonimos_a_clave[unidad.strip()]}\" for cantidad, unidad in coincidencias]\n",
    "                for k in presentaciones.keys():\n",
    "                    if k in my_pre_list[0]:\n",
    "                        return f\"{k} X {resultados[0]}\"\n",
    "                    if \"Und\" in my_pre_list[0] and (forma in [\"COMPRIMIDOS\", \"TABLETAS\"]):\n",
    "                        return f\"{k} X {valor[0]} COMP\"\n",
    "            return\n",
    "    return\n",
    "\n",
    "# Registrar la UDF\n",
    "primeras_presentaciones_udf = udf(primeras_presentaciones_udf, StringType())\n",
    "\n",
    "# Aplicar la UDF al DataFrame de veritrade\n",
    "df_veritrade_spark_ite7 = df_veritrade_spark_ite6.withColumn(\"PRESENTACION\", primeras_presentaciones_udf(col(\"FK_SENASA_ID\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType\n",
    "\n",
    "unidades_dict2 = {\n",
    "    'KG': ['KG','KGS', 'KILOGRAMOS', 'KILOS'],\n",
    "    'GR': ['GR','GRAMOS','G','GRMS','GRS'],\n",
    "    'LT': ['LT', 'LTR','LTS','LTRS','LTROS', 'LITROS', 'LITRO','L'],\n",
    "    'ML': ['ML'],\n",
    "    'UND':[\"UND\",\"UNIDADES\",\"UNID.\"]\n",
    "}\n",
    "\n",
    "unidad_map = {unit: std for std, units in unidades_dict2.items() for unit in units}\n",
    "\n",
    "def encontrar_unidad_medida(texto):\n",
    "    texto = texto.upper()\n",
    "    texto = texto.replace(\"X\", \" \")\n",
    "    texto = texto.replace(\"/\", \" \")\n",
    "    pattern = r'(?<!\\S)(\\d+(?:[.,]\\d+)?)\\s*(' + '|'.join(re.escape(unit.strip()) for units in unidades_dict2.values() for unit in units) + r')\\b'\n",
    "    coincidencias = re.findall(pattern, texto)\n",
    "    resultados = [f\"{cantidad.replace(',', '.')} {unidad_map[unidad.strip()]}\" for cantidad, unidad in coincidencias if unidad.strip() in unidad_map]\n",
    "    return resultados\n",
    "\n",
    "\n",
    "encontrar_unidad_udf = udf(encontrar_unidad_medida, ArrayType(StringType()))\n",
    "\n",
    "# Aplicar la UDF y crear una nueva columna\n",
    "df_veritrade_spark_ite8 = df_veritrade_spark_ite7.withColumn(\"UNIDAD\", encontrar_unidad_udf(col(\"Descripcion Comercial\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veritrade_spark_ite9 = df_veritrade_spark_ite8.withColumn(\n",
    "    \"PRESENTACION\",\n",
    "    F.when(col(\"PRESENTACION\").isNull(), indicar_agricola_udf(col(\"DES_COM\"))).otherwise(col(\"PRESENTACION\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "presentaciones_vacias = df_veritrade[df_veritrade['PRESENTACION'] == '']['FK_SENASA_ID'].index.tolist()\n",
    "\n",
    "sinonimos_a_clave_presentacion = {}\n",
    "for clave, sinonimos in presentaciones.items():\n",
    "    for sinonimo in sinonimos:\n",
    "        sinonimos_a_clave_presentacion[sinonimo.strip()] = clave.strip()\n",
    "\n",
    "sinonimos_a_clave_extra = {}\n",
    "for clave, sinonimos in unidades_dict2.items():\n",
    "    for sinonimo in sinonimos:\n",
    "        sinonimos_a_clave_extra[sinonimo] = clave\n",
    "\n",
    "pattern = r'(?<!\\S)(\\d+(?:[.,]\\d+)?)\\s*(' + '|'.join(re.escape(unit) for unit in sinonimos_a_clave_extra.keys()) + r')\\b'\n",
    "pattern_solo_valor = r'(?<!\\S)(\\d+(?:[.,]\\d+)?)(?=\\s*[a-zA-Z])'\n",
    "\n",
    "def obtener_presentacion(cadena):\n",
    "    cadena = cadena.strip()  # Eliminar espacios innecesarios\n",
    "    return sinonimos_a_clave_presentacion.get(cadena, cadena)  # Devuelve la clave o la misma cadena si no se encuentra\n",
    "\n",
    "def encontrar_presentaciones(texto, presentaciones):\n",
    "    texto = texto.upper()\n",
    "    encontrados = []\n",
    "\n",
    "    for clave, sinonimos in presentaciones.items():\n",
    "        for sinonimo in sinonimos:\n",
    "            if sinonimo.strip() in texto:\n",
    "                encontrados.append(clave)\n",
    "                break\n",
    "\n",
    "    return list(set(encontrados))\n",
    "\n",
    "\n",
    "for idx in presentaciones_vacias:\n",
    "    id_senasa = df_veritrade.loc[idx, \"FK_SENASA_ID\"]\n",
    "    forma = df_senasa.loc[df_senasa[\"ID\"] == id_senasa, \"DETALLE_VAR4\"].values\n",
    "\n",
    "    valor_unidad_medida=[]\n",
    "\n",
    "    if forma.size > 0:  # Asegúrate de que hay al menos un elemento\n",
    "        forma_str = forma[0]  # Obtén el primer elemento\n",
    "        if isinstance(forma_str, str):\n",
    "            try:\n",
    "                forma_list = ast.literal_eval(forma_str)\n",
    "                my_set=set({})\n",
    "                my_set_unidad=set({})\n",
    "                for i in forma_list:\n",
    "                    valor=i.split(\" \")\n",
    "                    if len(valor)>=3:\n",
    "                        my_set.add(valor[0])\n",
    "                        my_set_unidad.add(valor[-1])\n",
    "                if len(my_set)==1:\n",
    "                    my_pres=list(my_set)\n",
    "                    my_pres=my_pres[0]  \n",
    "                    forma_str=forma_str.upper()\n",
    "                    coincidencias_valor_unidad_medida = re.findall(pattern, forma_str)\n",
    "                    resultados = [f\"{cantidad.replace(',', '.')} {sinonimos_a_clave_extra[unidad.strip()]}\" for cantidad, unidad in coincidencias_valor_unidad_medida]    #TIPO LISTA\n",
    "                    valor_unidad_medida_veritrade = df_veritrade.loc[idx, \"UNIDAD\"]\n",
    "                    encontrado = False\n",
    "                    if len(valor_unidad_medida_veritrade)==0:\n",
    "                        pass\n",
    "                    else:\n",
    "                        #SOLO FUNCIONA PARA LOS CASOS QUE NO SEAN TAB NI COMP\n",
    "                        for result in resultados:\n",
    "                            for result2 in valor_unidad_medida_veritrade:\n",
    "                                if result==result2:\n",
    "                                    my_pres=obtener_presentacion(my_pres)\n",
    "                                    cad_pres=my_pres+\" X \"+result2\n",
    "                                    df_veritrade.loc[idx, \"PRESENTACION\"]=cad_pres\n",
    "                                    encontrado=True\n",
    "                                    break\n",
    "                                else:\n",
    "                                    pass\n",
    "                            if encontrado:\n",
    "                                break\n",
    "                    \n",
    "                    if (df_veritrade.loc[idx, \"FORMA_FARMACEUTICA\"]==\"TABLETAS\" or df_veritrade.loc[idx, \"FORMA_FARMACEUTICA\"]==\"TABLETAS INTRAUTERINAS\") and encontrado==False:\n",
    "                        valor=re.findall(pattern_solo_valor, df_veritrade.loc[idx,\"Descripcion Comercial\"])\n",
    "                        valor = [numero.replace(',', '.') for numero in valor]\n",
    "                        for i in range(len(valor)):\n",
    "                            valor[i]=valor[i]+\" UND\"\n",
    "                        encontrado_tableta=False\n",
    "                        for veri in valor:\n",
    "                            for sena in resultados:\n",
    "                                if veri==sena:\n",
    "                                    my_pres=obtener_presentacion(my_pres)\n",
    "                                    cad_pres=my_pres+\" X \"+sena\n",
    "                                    cad_pres=cad_pres.replace(\"UND\",\"TAB\")\n",
    "                                    df_veritrade.loc[idx, \"PRESENTACION\"]=cad_pres\n",
    "                                    encontrado_tableta=True\n",
    "                                    break\n",
    "                            if encontrado_tableta:  # Si se encontró una coincidencia, salir del bucle externo\n",
    "                                break\n",
    "                        \n",
    "                    if (df_veritrade.loc[idx, \"FORMA_FARMACEUTICA\"]==\"COMPRIMIDOS\" or df_veritrade.loc[idx, \"FORMA_FARMACEUTICA\"]==\"COMPRIMIDOS MASTICABLES\") and encontrado==False:\n",
    "                        valor=re.findall(pattern_solo_valor, df_veritrade.loc[idx,\"Descripcion Comercial\"])\n",
    "                        valor = [numero.replace(',', '.') for numero in valor]\n",
    "                        for i in range(len(valor)):\n",
    "                            valor[i]=valor[i]+\" UND\"\n",
    "                        \n",
    "                        encontrado_comprimido=False\n",
    "                        for veri in valor:\n",
    "                            for sena in resultados:\n",
    "                                if veri==sena:\n",
    "                                    my_pres=obtener_presentacion(my_pres)\n",
    "                                    cad_pres=my_pres+\" X \"+sena\n",
    "                                    cad_pres=cad_pres.replace(\"UND\",\"COMP\")\n",
    "                                    df_veritrade.loc[idx, \"PRESENTACION\"]=cad_pres\n",
    "                                    encontrado_comprimido=True\n",
    "                                    #print(idx)\n",
    "                                    break\n",
    "                            \n",
    "                            if encontrado_comprimido:  # Si se encontró una coincidencia, salir del bucle externo\n",
    "                                break  \n",
    "                else:\n",
    "                    forma_str=forma_str.upper()\n",
    "                    #print(\"tiene mas de una presentacion\")\n",
    "                    resultado_veritrade=encontrar_presentaciones(df_veritrade.loc[idx,\"Descripcion Comercial\"], presentaciones) #SI\n",
    "                    resultado_senasa=encontrar_presentaciones(forma_str, presentaciones)                                        #SI\n",
    "                    if len(resultado_veritrade)==0:\n",
    "                        pass\n",
    "                    else:\n",
    "                        salir = False\n",
    "\n",
    "                        for veri in resultado_veritrade:\n",
    "                            if salir:  # Verifica si se debe salir\n",
    "                                break\n",
    "                            for sena in resultado_senasa:\n",
    "                                if veri == sena:\n",
    "                                    valor = re.findall(pattern_solo_valor, df_veritrade.loc[idx, \"Descripcion Comercial\"])\n",
    "                                    valor = [numero.replace(',', '.') for numero in valor]\n",
    "                                    for li in forma_list:\n",
    "                                        for val in valor:\n",
    "                                            if (li.startswith(sena)) and (val in li):\n",
    "                                                partes = li.split(\" \")\n",
    "                                                parte_um = partes[-1].upper()\n",
    "\n",
    "                                                if parte_um==\"UND\":\n",
    "                                                    if (df_veritrade.loc[idx, \"FORMA_FARMACEUTICA\"]==\"TABLETAS\" or df_veritrade.loc[idx, \"FORMA_FARMACEUTICA\"]==\"TABLETAS INTRAUTERINAS\"):\n",
    "                                                        cadena = f\"{sena} X {val} TAB\"\n",
    "                                                        df_veritrade.loc[idx, \"PRESENTACION\"] = cadena\n",
    "                                                        salir = True\n",
    "                                                        break\n",
    "                                                    elif (df_veritrade.loc[idx, \"FORMA_FARMACEUTICA\"]==\"COMPRIMIDOS\" or df_veritrade.loc[idx, \"FORMA_FARMACEUTICA\"]==\"COMPRIMIDOS MASTICABLES\"):\n",
    "                                                        cadena = f\"{sena} X {val} COMP\"\n",
    "                                                        df_veritrade.loc[idx, \"PRESENTACION\"] = cadena\n",
    "                                                        salir = True\n",
    "                                                        break\n",
    "                                                else:\n",
    "                                                    cadena = f\"{sena} X {val} {parte_um}\"\n",
    "                                                    df_veritrade.loc[idx, \"PRESENTACION\"] = cadena\n",
    "                                                    salir = True \n",
    "                                                    break\n",
    "                                        if salir:  # Verifica si se debe salir después del bucle de valor\n",
    "                                            break\n",
    "                                if salir:  # Verifica nuevamente después del bucle de sena\n",
    "                                    break\n",
    "\n",
    "                                    #STARTS WITH Y CONTAINS\n",
    "\n",
    "            except (ValueError, SyntaxError):\n",
    "                print(\"Error al evaluar la cadena.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/19 13:06:37 WARN DAGScheduler: Broadcasting large task binary with size 1153.0 KiB\n",
      "24/11/19 13:06:46 WARN DAGScheduler: Broadcasting large task binary with size 1156.7 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark import StorageLevel\n",
    "\n",
    "df_veritrade_spark_ite8.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "\n",
    "df=df_veritrade_spark_ite8.toPandas()\n",
    "\n",
    "df.to_excel(\"output_geriax.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Partida Aduanera</th>\n",
       "      <th>Descripcion de la Partida Aduanera</th>\n",
       "      <th>Aduana</th>\n",
       "      <th>DUA / DAM</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Cod. Tributario</th>\n",
       "      <th>Exportador</th>\n",
       "      <th>Importador</th>\n",
       "      <th>Kg Bruto</th>\n",
       "      <th>Kg Neto</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR8</th>\n",
       "      <th>DETALLE_VAR8</th>\n",
       "      <th>NUMERO_DE_PALABRAS</th>\n",
       "      <th>DES_PROD</th>\n",
       "      <th>DES_PROD2</th>\n",
       "      <th>DES_PROD3</th>\n",
       "      <th>DES_PROD4</th>\n",
       "      <th>DES_PROD5</th>\n",
       "      <th>PRESENTACION</th>\n",
       "      <th>UNIDAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3004502000</td>\n",
       "      <td>DEMAS MEDICAMENTOS P` USO VETERINARIO Q` CONTE...</td>\n",
       "      <td>MARITIMA DEL CALLAO</td>\n",
       "      <td>005393 | 3</td>\n",
       "      <td>2021-01-25</td>\n",
       "      <td>20250406941</td>\n",
       "      <td>AGROVET MARKET S.A</td>\n",
       "      <td>QUALITY CO. FOR VET. MED. TRADE</td>\n",
       "      <td>12.15</td>\n",
       "      <td>11.54</td>\n",
       "      <td>...</td>\n",
       "      <td>PREVENCION_ENFERMEDAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ARTROSAMINE TABLETAS PALATABLES</td>\n",
       "      <td>ARTROSAMINE TABLETAS PALATABLES</td>\n",
       "      <td>ARTROSAMINE TABLETAS PALATABLES</td>\n",
       "      <td>ARTROSAMINETABLETASPALATABLES</td>\n",
       "      <td>ARTROSAMINETABLETASPALATABLES</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Partida Aduanera                 Descripcion de la Partida Aduanera  \\\n",
       "0        3004502000  DEMAS MEDICAMENTOS P` USO VETERINARIO Q` CONTE...   \n",
       "\n",
       "                Aduana   DUA / DAM      Fecha  Cod. Tributario  \\\n",
       "0  MARITIMA DEL CALLAO  005393 | 3 2021-01-25      20250406941   \n",
       "\n",
       "           Exportador                       Importador  Kg Bruto  Kg Neto  \\\n",
       "0  AGROVET MARKET S.A  QUALITY CO. FOR VET. MED. TRADE     12.15    11.54   \n",
       "\n",
       "   ...                   VAR8 DETALLE_VAR8  NUMERO_DE_PALABRAS  \\\n",
       "0  ...  PREVENCION_ENFERMEDAD          NaN                 3.0   \n",
       "\n",
       "                          DES_PROD                        DES_PROD2  \\\n",
       "0  ARTROSAMINE TABLETAS PALATABLES  ARTROSAMINE TABLETAS PALATABLES   \n",
       "\n",
       "                         DES_PROD3                      DES_PROD4  \\\n",
       "0  ARTROSAMINE TABLETAS PALATABLES  ARTROSAMINETABLETASPALATABLES   \n",
       "\n",
       "                       DES_PROD5 PRESENTACION  UNIDAD  \n",
       "0  ARTROSAMINETABLETASPALATABLES         None      []  \n",
       "\n",
       "[1 rows x 73 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pyspark import StorageLevel\n",
    "\n",
    "df_veritrade_spark_ite6.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "\n",
    "df_veritrade_spark_ite6.write.csv(\"output.csv\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PARA LOS QUE NO ENCUENTRA EN SENASA\n",
    "indices_no_encontrado = df_veritrade[df_veritrade[\"FK_SENASA_ID\"] == \"\"].index.tolist()\n",
    "\n",
    "#SE AMARRA UN NO ENCONTRADO CON ALIMENTO\n",
    "def verificar_empieza_alimento(texto):\n",
    "    if texto.startswith(\"ALIMENTO\"):\n",
    "        return \"Alimento\"\n",
    "    elif texto.startswith(\"ALMNTO.\"):\n",
    "        return \"Alimento\"\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "def verificar_contiene_alimento(texto):\n",
    "    return \"ALIMENTO\" in texto\n",
    "\n",
    "for idx in indices_no_encontrado:\n",
    "    desc_comer_raw = df_veritrade.loc[idx, \"Descripcion Comercial\"].strip().upper()\n",
    "    if verificar_empieza_alimento(desc_comer_raw):\n",
    "        df_veritrade.loc[idx, \"TIPO_PRODUCTO\"] = \"Alimento\"\n",
    "        continue\n",
    "\n",
    "    if verificar_contiene_alimento(desc_comer_raw):\n",
    "        df_veritrade.loc[idx, \"TIPO_PRODUCTO\"] = \"Alimento\"\n",
    "\n",
    "#PARA LOS QUE NO ENCUENTRA EN SENASA\n",
    "indices_no_encontrado = df_veritrade[df_veritrade[\"FK_SENASA_ID\"] == \"\"].index.tolist()\n",
    "    \n",
    "def verificar_contiene_agricola(texto):\n",
    "    if \"AGRICOLA\" in texto:\n",
    "        return True\n",
    "    elif \"AGRÍCOLA\" in texto:\n",
    "        return True\n",
    "    elif \"AGRICULTURA\" in texto:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "for idx in indices_no_encontrado:\n",
    "    desc_comer_raw = df_veritrade.loc[idx, \"Descripcion Comercial\"].strip().upper()  # Normalizar la descripción\n",
    "    filtro_avanzado=df_veritrade.loc[idx, \"TIPO_PRODUCTO\"]\n",
    "    if verificar_contiene_agricola(desc_comer_raw) and filtro_avanzado==\"\":\n",
    "        df_veritrade.loc[idx, \"TIPO_PRODUCTO\"] = \"Agrícola\"\n",
    "\n",
    "#df_veritrade.to_excel(\"VERITRADE_pruebas_01102024.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_veritrade_spark_ite4=df_veritrade_spark_ite3\n",
    "df_veritrade_spark_ite4=df_veritrade_spark_ite4.coalesce(4)\n",
    "df_veritrade_spark_ite4.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_particiones_veritrade = df_veritrade_spark_ite3.rdd.getNumPartitions()\n",
    "#print(f\"Número de particiones en df_veritrade_spark: {num_particiones_veritrade}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_veritrade_spark_ite3.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_output = df_veritrade_spark_ite6.toPandas()\n",
    "\n",
    "#df_output.to_excel(\"output_final.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_veritrade_spark_ite6=df_veritrade_spark_ite6.repartition(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_veritrade_spark_ite6.write.csv(\"hdfs://localhost:9000/alexander/output.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_veritrade_spark_ite6.count())\n",
    "#print(df_veritrade_spark_ite6.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_veritrade_spark_ite6.write.csv(\"output.csv\", header=True, mode=\"overwrite\")\n",
    "#df_veritrade_spark_ite6.coalesce(1).write.csv(\"hdfs://localhost:9000/alexander/output.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
